# 2) 가중치

#############KEYWORD##################
# 임계값 : 1과 0을 출력하는 기준.
# 활성함수 : 퍼셉트론이나 신경망의 뉴련을 활성화 시키는 함수 혹은 방정식
# 가중치 : 퍼셉트론의 학습 목표는 학습 벡터를 두 부류로 선형 분류하기 위한 선형 경계를 찾는 것. 가중치는 이러한 선형 경계의 방향성 또는 형태를 나타내는 값.

#여러개의 input 값을 입력 받고 각각의 가중치를 곱해서 계산 한 뒤 더해준 다음 출력 값을 거치는 과정을 거친다.
#가중치는 각각의 입력신호(input)에 따라 모두 다르며 고유한 값이다. 퍼셉트론은 이 가중치와 입력 값의 곱의 총 합이
#일정 기준을 초과하면 1, 이하면 0 을 출력해준다.
#여기서 1과 0을 출력하는 기준이 되는 값을 임계 값이라고 하고 보통 θ로 표현한다.
#이 과정을 수식으로 표현하면?
#       |- 0 (w1x1 + ... + wnxn <= θ
#  y =  |
#       |- 1 (w1x1 + ... + wnxn > θ

#이와 같이 퍼셉트론이나 신경망의 뉴런을 활성화 시키는 함수 혹은 방정식을 활성함수(Activation Function) 이라고 한다.



#즉 가중치와 입력 값의 곱의 총 합이 임계 값을 넘기면 1, 그렇지 않으면 0을 출력 값 y는 가지게 된다.
#여기서 가중치는 각 신호(input)가 결과에 주는 영향력의 크기라고 생각 할 수 있다.
#왜냐하면 동일한 입력 값이 입력되었을 경우 가중치가 크면 클수록 해당 신호가 가지는 값이 더 커지기 때문.
#예를들어 입력값 3개 x1,x2,x3이고 각각의 가중치가 w1,w2,w3인 단층 퍼셉트론을 예로 들면
#이 퍼셉트론의 출력 값은 다음과 같다.

#      |-- 0 (w1x1 + w2x2 + w3x3 <= θ)
#  y = |
#      |-- 1 (w1x1 + w2x2 + w3x3 > θ)

# 이 퍼셉트론에 입력 값으로 전부 1 (1,1,1)을 입력하는 경우 입력 값의 합은
# w1 + w2 + w3 이다.
# 이 경우 각 입력 값의 가중치는 임계 값에 대한 지분으로 생각해 볼 수 있다.
# 따라서 가중치가 크면 클수록 해당 가중치의 입력 값은 임계 값에 대한 영향력이 더 크다고 할 수 있다.







