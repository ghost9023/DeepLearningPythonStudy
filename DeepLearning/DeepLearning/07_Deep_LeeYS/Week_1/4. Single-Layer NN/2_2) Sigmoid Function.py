#시그모이드 함수

#######KEYWORD##########
#자연상수 :



########################


# 우선 시그모이드 함수를 이해하기 위해서 자연상수가 무엇인지 알아보자.
# 자연상수 e는 수학 통계 화학 물리 전반에 걸쳐 널리 사용되는 상수이다.
# 자연 상수는 2.718인 비 순환 소수인 무리수이다. 원주율을 파이로 쓰는 것처럼 수학자 오일러의 첫 글자인 E를 따서 e기호를 써서 사용.
# 여러 자연적 현상들을 수식으로 설명할 때 이 자연 상수를 통해 대부분 설명할 수 있어서 자연 상수라고 부른다.
# 자연 상수는 미적분에서 특이한 성질을 지니고 있다.
#   d
#  --- e^x = e^x
#   dx
#
#
#
#
#시그모이드 함수의 함수식
#
#              1
# h(x) = -------------
#          1 + e^-x
#
#

#시그모이드 함수의 계산 결과는 항상 0과 1 사이에 있다. 계단함수와 시그모이드 함수를 각각 파이썬 matplotlib을 이용해서 그려보면..

#계단함수
import matplotlib.pylab as plt
import numpy as np
def step_function(x):
    return np.array(x>0, dtype=np.int)

x=np.arange(-5.0,5.0,0.1)
y=step_function(x)
plt.plot(x,y)
plt.ylim(-0.1,1.1)
plt.show()

#기본적인 계단 함수는 0을 기준으로 출력값이 0과 1로 나뉘는 것을 볼 수 있다. 그래프 형태가 계단처럼 생겨서 계단함수라고 부르는 것.
#다음으로 시그모이드 함수를 파이썬 함수로 구현해보고 역시 그래프를 그려보자.
#시그모이드 함수
import numpy as np
import matplotlib.pylab as plt
def sigmoid(x):
    return 1/(1+np.exp(-x))
x=np.arange(-5.0,5.0,0.1)
y=sigmoid(x)
plt.plot(x,y)
plt.ylim(-0.1,1.1)
plt.show

#시그모이드 함수에서 시그모이드란 S자 모양이라는 뜻으로 계단 함수가 계단 처럼 생겼다고 계단 함수라고 부르는 것처럼
#시그모이드 함수가 S자 모양이어서 시그모이드 함수라고 부른다. 시그모이드 함수와 계단 함수를 한 좌표축에 비교하면
#시그모이드 함수는 부드러운 곡선으로 입력에 따라 출력값이 연속적으로 부드럽게 바뀐다.
#하지만 계단 함수는 0을 기점으로 출력값이 0에서 1로 확 바뀐다. 또한 시그모이드 함수는 0과 1사이의
#모든 값을 출력값으로 내보낼 수 있지만 계단 함수는 0 아니면 1만 내보낼 수 있는 점이 시그모이드 함수와의 차이점.
#바로 이러한 점이 퍼셉트론보다 복잡하고 정교한 신경망구조에서 계단 함수를 사용하지 않는점.
#단층 퍼셉트론에서 선형 방정식을 활성함수로 사용하지만 다층 퍼셉트론에선 비선형 방정식을 활성함수로 사용한 것과 마찬가지로 신경망도
#비선형 방정식을 활성함수로 사용해야만 한다.
#그렇기 때문에 시그모이드 함수와 같은 비선형 함수를 사용하는 것.
#그렇다면 최신 트렌드에서 사용하는 ReLU함수를 알아보자.


